<?xml version="1.0" standalone="no"?>
<!DOCTYPE chapter SYSTEM "minidocbook.dtd" [
	<!ENTITY lexi.app "<application>Lexi</application>">
]>

<chapter id="commands">
	<title>Commands</title>	<!-- TODO: term -->

	<para>Lexical analysers are described to &lexi.app; by a
		sequence of commands. This section provides an explanation of
		each possible command, and explains their respective
		intended uses.</para>

	<section id="pre-pass-mappings">
		<title>Pre-pass Mappings</title>

		<para>The lexical analysis runs in two passes. The first pass,
			or <quote>pre-pass</quote> stage permits replacements to be substituted
			before the main pass, under which tokenisation takes place.
			This gives a convenient mechanism for expressing trigraph-like
			substitutions as found in C. The syntax to define pre-pass
			replacements is:</para>

		<!-- TODO: not real BNF! -->
		<programlisting language="bnf">MAPPING sequence + "->" + char ;</programlisting>

		<para>The string on the right (i.e. the value with which the
			matched string is replaced) may only contain one character,
			or an escape sequence which yields one character.</para>

		<para>For example, to replace the trigraph <literal>??=</literal>
			with a single <literal>#</literal>:</para>

		<programlisting language="lxi">MAPPING "??=" -> "#" ;</programlisting>

		<para>This would replace instances of <literal>??=</literal>
			with <literal>#</literal> before
			any tokenisation takes place. So the input
			<literal>a??=b</literal> would
			match the token definition:</para>

		<programlisting language="lxi">TOKEN "a#b" -> a ;</programlisting>

		<para>(and so would simply <literal>a#b</literal>, as usual).</para>

		<para>A group may be included in the character sequence to
			be replaced. For example:</para>

		<programlisting language="lxi">MAPPING "[alpha]" -> " " ;</programlisting>

		<para>will replace any alphabetic character by a blank,
			assuming the <quote>alpha</quote> group is suitably
			defined at that point.
			See <xref linkend="character-sets-sequences"/>
			for details of including groups in sequences.</para>

		<para> It is possible to use groups to NOT match characters in the group.</para>

		<programlisting language="lxi">MAPPING "[^alpha]" -> " " ;</programlisting>

		<para> will replace any non alpha character by a blank.</para>

		<para>Mappings are substituted repeatedly until no further
			mappings match. The order of replacement for mappings
			matching strings of equal length is undefined,
			and so it is an error to define a mapping which produces
			a character used at the start of any mapping, including
			itself. For example:</para>

		<programlisting language="lxi">MAPPING "???" -> "?" ;</programlisting>

		<para>is illegal. To see why, consider the input
			<quote><literal>aab</literal></quote> for
			the (illegal) mappings:</para>

		<programlisting language="lxi">MAPPING "aa" -> "x" ;
MAPPING "xb" -> y ;</programlisting>

		<para>Since the order of substitution for mappings matching
			strings of equal length is undefined, it is
			unclear if this will result in <quote>xb</quote> or
			<quote>y</quote>. Notice that
			C does not demand a <quote>???</quote> trigraph
			- perhaps for this very reason (or perhaps simply
			because it is redundant).
			This restriction applies no matter how the string
			defining the characters to be mapped is formed: for
			example, it is also illegal to define a mapping which maps
			to a character present in a group included at the start
			of another mapping.</para>

		<para>Mappings bind from left to right. For example:</para>

		<programlisting language="lxi">MAPPING "ab" -> "d" ;
MAPPING "bc" -> "d" ;</programlisting>

		<para>For the input <quote>abc</quote> will produce
			<quote>db</quote>, not <quote>ad</quote>.</para>

		<para>Mappings matching sequences of longer lengths
			are replaced with higher precedence than mappings
			matching shorter lengths of the same values
			beginning the longer sequences. For example:</para>

		<programlisting language="lxi">MAPPING "abcdef" -> "x" ;
MAPPING "abcd" -> "y" ;</programlisting>

		<para>for the input <quote><literal>abcdef</literal></quote>
			will produce <quote><literal>x</literal></quote>,
			not <quote><literal>yef</literal></quote>.</para>
		<!-- TODO: ditto tokens? -->
	</section>

	<section id="group-definitions">
		<title>Character Group Definitions</title>

		<para>A group is an unordered sets of characters; groups
			name these sets for use in <!-- TODO: which strings? -->
			strings <!-- TODO: think up a name for group inclusions -->.
			The syntax of a group definition is:</para>

		<programlisting language="bnf">group-defn := "GROUP" + identifier + "=" + chars ;</programlisting>
		<!-- TODO: not identifier, but name (we don't want to include
			sid-identifiers!) -->

		<para>The <code>identifier</code> specified is the name
			by which the group may be referenced.</para>

		<para>For example, the following are valid group definitions:</para>

		<programlisting language="lxi">GROUP alpha    = {A-Z} + {a-z} + "_" ;
GROUP digit    = {0-9} ;
GROUP odds     = "13579" ;
GROUP even     = "02468" ;
GROUP vowels   = "aeiou" ;
GROUP anything = "atrf" + "HGMP" + {0-9} ;</programlisting>

		<para>Groups may include the sets of previously-defined
			groups. Any character in the referenced set will be
			included into the group definition. For example:</para>

		<programlisting language="lxi">GROUP hexdigit = "[digit]ABCDEFabcdef" ;
GROUP alphanum = "[alpha]" + {0-9} ;</programlisting>

		<para>assuming the groups <literal>alpha</literal> and
			<literal>digit</literal> have already
			been defined at that point.
			See <xref linkend="character-sets-sequences"/> for details of the
			syntax for the chars production.</para>

		<para>Groups may not contain characters which are present
			in other groups (i.e. they may not overlap). See the
			<xref linkend="token-definitions"/> section for further
			discussion of why this is so.</para>
		<!-- TODO: NEW UNDEFINED BEHAVIOUR -->

		<para>Macros to test if a character belongs to a group
			are provided in the generated code, of the form
			<code>is_groupname()</code>. These must be
			passed the index into the look-up table containing
			the given character, obtained by <code>lookup_char(c)</code>.
			For example:</para>

		<programlisting language="c">is_alpha(lookup_char('a'))</programlisting>
		<!-- TODO: repetition: this is in Interface -->

		<para>would yield true, assuming the group <literal>alpha</literal>
			is suitably defined.</para>

		<!-- TODO: explain what groups are legal, undefined, etc.
			Overlapping, for example? -->

		<para>The group name <quote>white</quote> may not be used for groups other
			than the whitespace definition; see
			<xref linkend="whitespace-definitions"/> for details.</para>

		<para>A group name is unique amongst groups; groups may
			only be defined once.</para>
		<!-- TODO: unique amongst what else? Think in terms of namespaces;
			somewhere we should explain namespaces for identifiers -->
	</section>

	<section id="whitespace-definitions">
		<title>Whitespace Definition</title>

		<para>Consecutive whitespace characters outside of tokens
			are skipped by the lexical analyser <emphasis>before</emphasis>
			each token is recognised.
			Whitespace is treated with the semantics of a
			single token delimiter. &lexi.app; specifies
			whitespace by the special group name <code>white</code>,
			which may not be used as an identifier to name other
			groups.</para>

		<para>For special cases where whitespace has significance (a common
			example is inside string literals), token definitions may call
			user-defined functions which purposefully circumvent the
			whitespace-skipping features of
			&lexi.app;.</para>

		<para>The syntax is the same as for any
			<xref linkend="group-definitions"/>, but with the
			special group name <code>white</code>:</para>

		<programlisting language="bnf">white-defn := "GROUP" + "white" + "=" + chars ;</programlisting>

		<para>The whitespace definition may be omitted, in which case
			it defaults to space, horizontal tabulation and
			newline. Therefore it is always present, even if the
			declaration is implicit. As with any group, it may not
			be defined multiple times.</para>

		<para>For example:</para>

		<programlisting language="lxi">GROUP white = " \t\n\r";</programlisting>

		<para>Aside from the additional semantics explained above,
			the whitespace group is present as any other group:
			it is present in the <acronym>API</acronym> as <code>is_white()</code>,
			and may be included in <xref linkend="character-sets-sequences"/>
			as <code>[white]</code>.</para>

		<!-- TODO: NEW UNDEFINED BEHAVIOUR -->
		<!-- if white contains the same characters as other tokens,
			it has precedence. however we call that illegal -->
		<para>It is illegal to define the whitespace group to
			contains characters which are present in token
			definitions, including groups which those tokens use.</para>
		<!-- TODO: rather, we should also say it's illegal to define
			tokens which use whitespace characters. -->
	</section>

	<section id="token-definitions">
		<title>Token Definitions</title>

		<para>Tokens are sequences of characters read by the lexical analyser
			and produced as output. Each token as a unique identifier,
			which is passed to code calling &lexi.app;,
			along with the characters read which form the token's
			spelling.<!-- TODO: not true: you need to store the spelling
			yourself --></para>

		<para>Tokens are usually the main component of a lexical analyser.
			In &lexi.app;'s case, the only situation in
			which there would be no token declarations is if the lexical
			analyser is to exclusively perform pre-pass mappings. The
			effect of specifying neither tokens nor pre-pass mappings
			is undefined.</para>

		<para>The syntax for specifying tokens is:</para>

		<programlisting language="bnf">token-defn := "TOKEN" + chars + "->" + action-list ;
command-list := "TOKEN" + chars + "->" command + "," + command-list ;</programlisting>

		<para>An command is either a return terminal command, a discard command,
			a function call command. Inline actions (sidlike) will be introduce in version 2.0
			but are not ready in trunk yet.</para>

		<variablelist>
			<varlistentry>
				<term>The token discard command</term>

				<listitem>
					<para>It is represented by the token <code>$$</code>.
						It should be in the last position. If this is the only
						instruction, the token will be read and its spelling
						discarded.</para>
				</listitem>
			</varlistentry>

			<varlistentry>
				<term>The return terminal command</term>

				<listitem>
					<para>A return terminal command is either a
						<application>Sid</application> identifier or a non prefixed identifier.</para>
							<programlisting language="bnf">return-terminal-command :=    $ + identifier ;
				| identifier ;</programlisting>

						<para>An example of these two forms:</para>

						<programlisting language="lxi">TOKEN "token1" -> $sid-identifier ;
TOKEN "token2" -> nonsid_identifier; </programlisting>

						<para>A <application>Sid</application> identifier is an identifier
							that will be prefixed by <code>lex_</code> or the prefix given
							in the <option>-t</option> option. Non prefixed identifiers will
							not be prefixed at all. The non prefixed form is considered
							obsolete and might be remove without notice.
							The first form of token definition states that upon
							encountering <quote>token1</quote> the lexer should return
							the terminal corresponding <quote>sid-identifier</quote>.
</para>
						<para>A return terminal command must appear last in the list
							of commands.</para>
				</listitem>
			</varlistentry>

			<varlistentry>
				<term>The function call command</term>

				<listitem>
					<para>A function call command has the form</para>

					<programlisting language="bnf">function-call-command :=  identifier + "(" + argument-list + ")" ;</programlisting>

					<para>An argument-list is a comma separated list.
						Here are examples of arguments:</para>

					<programlisting language="lxi">TOKEN "[alpha1][digit]" -> get_identifier1(##); // Old form, will probably be obsoleted calls get_identifier1(c0,c1)
TOKEN "[alpha2][digit]" -> get_identifier2(); // Old form equivalent to previous form will probably be obsoleted
TOKEN "[alpha3]" -> get_identifier3(#$); // calls get_identifier3() with no argument
TOKEN "[alpha4]a" -> get_identifier3(#); // calls get_identifier4()
TOKEN "[alpha4][digit]b" -> get_identifier4("globalbuffer", #1,#0); // calls get_identifier4(globalbuffer,c1,c0)
TOKEN "[alpha5]a" -> get_identifier5(#*); // should call get_identifier5(char*), not completely implemented yet.</programlisting>

					<para>where <code>c0, c1, c2, ...</code> matches the first, second and third
						character of the token. It is possible to combine the arguments
						(except for <code>#$</code> which is only valid if it is the only argument of the list.</para>

					<para>The return value of a function will be ignored unless this is the last
					  	function call in the command list, in which case it is expected
						to return a valid terminal. If you don't want it the last called function
						to return a terminal, you have to add a trailing discard <code>$$</code>:</para>

					<programlisting language="bnf">TOKEN "[digit]" -> push_buffer(#0), $$; // do not return a terminal.
TOKEN "[alpha]" -> get_identifier(#0); // return a terminal</programlisting>
				</listitem>
			</varlistentry>

			<varlistentry>
				<term>Inline action calls</term>

				<listitem>
					<para>An inline action call has the form</para>

					<programlisting language="lxi">(/*commaseparatedoutputlist*/) = &lt;action-name&gt;( /* commaseparatedargumentlist*/);</programlisting>

					<para><code> &gt; </code> <code> > &lt; </code> may or may not be removed from the
						syntax. The decision will happen prior to 2.0. The argumentlist can contain
						either local variables, <code>#</code> style of arguments.
						Actions and types must have been previously declared
						see <!-- TODO: insert reference --></para>
				</listitem>
			</varlistentry>
		</variablelist>

		<para>See <xref linkend="interface-terminals"/> for the C
			representation of the terminals returned by
			<code>read_token()</code>.</para>

		<para>The second form states that the lexer should return the result
			of the call to the given function identifier. See
			<xref linkend="interface-functions"/> for details of the
			function call made in C.</para>

		<para><!-- TODO: simple examples here --></para>

		<para>In more complex cases (most notably where tokens need include
			whitespace), tokens are mapped to user-defined functions.
			For example, for comments in a C-style language, the lexical
			analyser is expected to discard characters until the end
			of the comment is found. In &lexi.app;,
			this is specified as:</para>

		<programlisting language="lxi">TOKEN "/*" -> get_comment() ;</programlisting>
		<!-- TODO: right? -->

		<para>Where <code>get_comment()</code> is an externally defined
			function which simply reads characters until the corresponding
			<code>*/</code> is found. See the <!-- TODO -->functions
			section for further details of calling functions.</para>

		<para>In most languages, keywords are usually a subset of
			identifiers. In order to handle these and simplify the
			user-defined <code>read_identifier()</code> function
			(or equivalent), &lexi.app; provides
			the keywords mechanism discussed in
			<xref linkend="keyword-definitions"/>.</para>
		<!-- TODO: mention that most keywords are usually a subset of identifiers -->

		<para>Note that this example does not illustrating storing the
			characters read. A real-world case would usually store
			spellings in order to be useful to a later stage, such
			as parsing.</para>

		<!-- TODO: only defined once?  -->

		<para>Unlike many lexical analysers, tokens in
			&lexi.app; are not specified by regular
			expressions. However, as sequences of characters may contain
			references to groups (which are treated as sets), similar
			effects may be achieved for simple cases. For example:</para>

		<programlisting language="lxi">TOKEN "[alpha]" ->  get_identifier ();
TOKEN "$[alpha]" -> get_sid_identifier ();</programlisting>

		<para>assuming the group <quote>alpha</quote> is defined. Another example:</para>

		<programlisting language="lxi">TOKEN "A[digit]" -> $papersize ;</programlisting>

		<para>would match paper sizes such as such as <quote>A3</quote>,
			<quote>A4</quote> and so on. A token may only be defined once,
			but different tokens may share the same terminal or call the
			same function. So to extend our (rather lax) implementation of
			<acronym>ISO</acronym> 216 paper sizes:</para>

		<programlisting language="lxi">TOKEN "A[digit]" -> $papersize ;
TOKEN "A10" -> $papersize ;
TOKEN "C[digit]" -> $envelopesize ;
TOKEN "B[digit]" -> $envelopesize ;
TOKEN "DL" -> $envelopesize ;	/* BS 4264 specifies a transparent window for DL */
TOKEN "ID-[digit]" -> $identificationcardsize ;</programlisting>
			<!-- TODO: extend as "C[{0-3}]" in the future -->

		<para>Note that <quote>A10</quote> codes for the same lexeme as
			single-digit <quote>A</quote> sizes. See
			<xref linkend="function-calls"/> for further examples of
			multiple tokens sharing one function, and the <!-- TODO: sets -->
			for further examples of using sets within sequences.</para>

		<para>Using groups in this way is especially useful in combination
			with functions for reading variable-length tokens. For example:</para>

		<programlisting language="lxi">TOKEN "[alpha]" ->  get_identifier() ;
TOKEN "$[alpha]" -> get_sid_identifier() ;</programlisting>

		<para><!-- TODO: state ranges are undefined --></para>

		<!-- TODO: Kevin says:
			Remember, individual characters have priority over groups. But lexi
			doesn't handle subset analysis for groups. So

            GROUP alpha     =  {A-Z}+{a-z} ;
            GROUP lower     =  {a-z} ;
            TOKEN "[alpha]" -> get_identifier ()
            TOKEN "[lower]"  -> get_low_identifier () ;

       may not work correctly. lexi doesn't look  for  ambiguities  if  groups
       overlap.
		TODO: we defined overlap as illegal in the groups section;
			this is just explaining rationale -->

<!-- TODO: stated as undefined behaviour in Strings section
		<para>TODO: Kevin says:
       An empty string can be a token,
            TOKEN "" -> $default ;
       It really means that if no other token match, then the  lexer  will  eat
       one  character  and  return  $default.   If  this  token is not present
       lex_unknown would have been returned.
		</para>

TODO: we should make a sequence of undefined behaviours and check
if anybody uses them (or indeed if anybody uses lexi...)
-->

	</section>

	<section id="default-definition">
		<title>Default definition</title>

		<para>A new feature in 2.0 is the ability to specify actions (usually token return)
			by default. I.e:</para>

		<programlisting language="lxi">TOKEN "[alpha]" ->  get_identifier() ;
TOKEN DEFAULT -> $unknown ;</programlisting>

		<para>specify that the terminal <code>$unknown</code> should be returned upon encountering
			a sequence of character that cannot be mapped to any other specified token.</para>
	</section>

	<section id="keyword-definitions">
		<title>Keyword definitions</title>

		<para>The  syntax of keywords resembles the syntax
			used for tokens:</para>

		<programlisting language="bnf">keyword-defn := "KEYWORD" + string + "->" + either-identifier ;</programlisting>

		<para>For example:</para>

		<programlisting language="lxi">KEYWORD "keyword" -> $key ;
KEYWORD "special" -> get_special () ;</programlisting>

		<para>Usually  keywords are simply identifiers with a special
			meaning.  Using the main pass to identify keyword
			with the token constructs is possible but awkward
			since the spelling of keywords is usually a subset of the
			much bigger set of identifiers. The keyword construct
			facilitates the identification of keywords after
			a token has been found; they have effect only for
			the <option>-k</option> and are otherwise not present
			in the output generated by &lexi.app;.
			Therefore the only difference between keywords and
			tokens (and indeed their purpose) is the programmatic
			interface that they provide.<!-- TODO: and overlap! --><footnote>
				<para>This historic interface for producing keywords
					is expected to change drastically for the next version of
					&lexi.app;.</para>
			</footnote></para>

		<para>Code generated by &lexi.app; under
			the <option>-k</option> option consists of a succession
			of calls to define each keyword, one per <code>KEYWORD</code>
			statement:</para>

		<programlisting language="lxi">MAKE_KEYWORD ( "keyword", "lex_key" )
MAKE_KEYWORD ( "special", "get_special ()" )</programlisting>

		<para>where the identifier has been transformed according
			to the rules for <application>Sid</application>
			identifiers<!-- TODO: link -->.
			It is then left to the user to implement
			<code>MAKE_KEYWORD</code>,
			usually by way of a macro. The generated keyword
			code is intended to be included with a
			<code>#include</code> directive.
			Suppose that keyword.h contains the keyword code then
			building on existing token definitions, the
			intended use for keywords is as follows (for example with
			a lexer required to identify variable names):</para>

<!-- TODO: use read_identifier from above -->
		<programlisting language="lxi">KEYWORD "if" -> keyword_if ;
KEYWORD "else" -> keyword_else ;
TOKEN "[alpha]" -> get_variable() ;</programlisting>

		<para>Where and <code>get_variable()</code> checks to
			see if the given token is actually a keyword like so:</para>

		<programlisting language="c">&lt;type&gt; get_variable(int c) {
	char *token;
	/* token is pointed to the characters read */
	...
	#define MAKE_KEYWORD(A, B)\
		if (!strcmp(token, (A))) return(B);
	#include "keyword.h"
		return(lex_variable);
	...
}</programlisting>

		<para>Here <filename>keyword.h</filename> was generated by
			&lexi.app;'s <option>-k</option>. If the
			variable name read by <code>get_variable()</code> and
			pointed at by <code>char *token</code> is a keyword,
			<filename>keyword.h</filename>'s calls to <code>MAKE_KEYWORD()</code>
			will result in the string comparisons of <code>token</code>
			to each possible keyword in turn (that is, <code>token</code>
			is compared to <code>"if"</code> and <code>"else"</code>.
			If either of these match, the identifiers <code>keyword_if</code>
			and <code>keyword_else</code> are returned, respectively.
			Otherwise, if no keywords match, the token is known to
			be a variable name, and so <code>get_variable()</code>
			falls through to return the <code>lex_variable</code>
			identifier.</para>

		<para>Unlike functions associated with tokens, functions
			associated with keywords are generated to be called
			with no arguments passed:</para>

		<programlisting language="lxi">KEYWORD "sx" -> fx() ;</programlisting>

		<para>Results in the generated call:</para>

		<programlisting language="c">MAKE_KEYWORD("sx", fx());</programlisting>

		<para>And so <code>f()</code> should be declared to
			accept no parameters, that is of prototype:</para>

		<programlisting language="c">&lt;type&gt; f(void);</programlisting>

	<!-- TODO: does mapping a keyword to a function have a use-case? if not,
		can we disallow it? Perhaps good for FORTRAN style unreserved keywords?
		(the function could check to see if the symbol table holds that
		identifier; if it doesn't, then we know its a keyword) -->

<!--
<kevin2993> And I believe I was wrong at one point in the manpage saying that one 
            could replace a KEYWORD with aTOKEN and get an equivalent program 
            with a different interface
<kevin2993> The difference is the beginning of 
            keywordwithoutaseparatingwhitespace will be recognized as a token but 
            not as keyword if keyword is a keyword
-->

		<para><!-- TODO: example of PL/I-esque unreserved keywords --></para>
	</section>

	<section id="zone-definitions">
		<title>Zone Definitions</title>

		<para>Zones are the major new feature for 2.0. 
		  	A zone is a part of a file where lexing rules change. The general syntax is</para>

		<programlisting language="lxi">ZONE zonename : "entrytoken" [ -> $entry-terminal] ... "leavingtoken" [ ->$leaving terminal] {
 /*Zone body*/
}</programlisting>

		<para>Upon encountering the entry token, the lexer change the lexing rules and
		  use the ones defined in the zone body until it encounters the leaving token. Optionally,
		  a terminal may be returned on either zone entry or zone leaving (or both)
		  In the zone body, one can have whitespace definitions, group definitions, token definitions,
		  default token definitions, mappings and other zone definitions. Keyword definitions 
		  are not allowed inside zones for now but it is a planned feature.</para>

		<para>Zones are used in place of user defined functions. Their goal is to allow a better
			expressivity in the lxi language. For example, we can define comment using zones:</para>

		<programlisting language="lxi">ZONE comment: "/*" ... "*/"  {
	GROUP white = "";
	TOKEN DEFAULT -> $$; /* $$ means discard the token */
}

ZONE linecomment: "//" ... "\n"  {
	GROUP white = "";
	TOKEN DEFAULT -> $$; /* $$ means discard the token */
}</programlisting>

		<para>It is also possible to use zones to express strings:</para>

		<programlisting language="lxi">
ZONE string : "\"" -> clear_buffer(#$) [...] "\"" ->$string  {
	GROUP white = "";
	TOKEN DEFAULT -> push_buffer(#0), $$; 
}</programlisting>

		<para>It is planned to add buffers to lexi 2.1, removing the need for user function such as 
			push_buffer. The range operators <code>...</code> and <code>[...]</code> are equivalent. 
			To express identifiers,
			one need to use the <code>[...)</code> for which the leaving token is not 
			considered a part of the zone:</para>

		<programlisting language="lxi">ZONE string : "[alpha]" -> clear_buffer(#$) [...) "[^alphanum]" ->$identifier  {
	GROUP white = "";
	TOKEN DEFAULT -> push_buffer(#0), $$; 
}</programlisting>

		<para>Syntactic sugar for identifiers, comments and string should be added
		  	in either 2.1 or 2.2.</para>
	</section>

	<section id="type-definitions">
		<title>Type Definitions</title>

		<para>We can declare types in lexi. This will be used for type checking of
			instructions (inline actions mostly, see <!--TODO: put reference-->)
			that must happen upon encountering a token. Types declaration must only happen
			in the global zone. Here are examples:</para>

		<programlisting language="lxi">TYPE buffer;
TYPE integer;</programlisting>

		<para>There are several predefined types used by various action parameters;
			these need mapping to appropriate C types by <code>typedef</code> if used.
			The predefined types are:</para>

		<table>
			<title>Predefined Types</title>

			<col align="center"/>
			<col align="left"/>

			<thead>
				<tr>
					<th>Type</th>
					<th>Use</th>
				</tr>
			</thead>

			<tbody>
				<tr>
					<td><code>CHARACTER</code></td>
					<td>TODO: $# etc</td>
				</tr>
				<tr>
					<td><code>STRING</code></td>
					<td>TODO</td>
				</tr>
				<tr>
					<td><code>TERMINAL</code></td>
					<td>TODO: $xyz etc</td>
				</tr>
			</tbody>
		</table>
	</section>

	<section id="action-declaration">
		<title>Action prototypes</title>

		<para>Any inline actions called inside a list of instructions
		  must have been previously prototypes.</para>

		<programlisting language="bnf">action-decl := "ACTION" + identifier [ + ":" + "(" + typelist+")" + "->" + "(" + typelist+")";</programlisting>

		<para>Here is an example:</para>

		<programlisting language="lxi">ACTION actionname : (:TYPE1,:TYPE2) ->(:TYPE3,:TYPE4);</programlisting>
	</section>


<!--
	<section>
		<title>Blocks</title>

		<para>TODO. what're these even for? just IFs, I think. if so,
			merge them - we have no scope etc, so there's no other purpose</para>
	</section>
-->

</chapter>

